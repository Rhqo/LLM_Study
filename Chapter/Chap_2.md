# Chap. 2 LLM을 이용한 의미 기반 검색

## 작업

비대칭적 의미 기반 검색

입력 쿼리의 의미 정보(크기 등)와 검색 시스템이 검색해야 하는 문서/정보 사이에 불균형있 있다.

## 솔루션 개요

## 구성 요소

텍스트 임베더

OpenAI의 임베딩 엔진

BERT의 Sentence Transformer (Bi-encoder)

→ Bi-encoder: 입력 텍스트와 출력 텍스트를 인코딩하여 유사도가 높아지도록 훈련됨

문서 청킹

- Max token window chunking
    
    중복 O, 중복 X
    
- 자연 구분자 기준 청킹
- Clustering
    
    Scikit-learn의 병합 클러스터링 인스턴스
    
- 전체 문서 사용

벡터 데이터베이스

- 파인콘

오픈 소스 대안

- Pgvector
- Weaviate

검색 결과 재순위화

- Sentence Transformer 라이브러리의 Cross-Encoder: 두개의 입력 받고 두번째가 첫번째에 얼마나 관련이 있는지 점수로 예측하는 트랜스포머 모델.
- BM25: 문서 내 쿼리 용어의 빈도에 따라 결과를 순위화, 용어의 근접성과 역문서 빈도를 고려.

API

## 통합

성능

---

LLM을 이용한 의미 기반 검색 시스템의 개발 과정을 한 번 진행했다.

`텍스트 임베더`는 텍스트를 벡터로 표현

`문서 청킹`은 문서를 쪼개기

Pinecone의 `벡터 데이터베이스`를 사용

`크로스-인코더`와 `바이-인코더`를 사용한 `검색 결과 재순위화`

파이썬으로 `API`를 구축하기 위한 FastAPI