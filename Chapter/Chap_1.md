# Chap. 1 LLM

## LLM?

### 정의

Large Language Model

사람의 언어, 코드 등을 이해하고 생성하기 위해 설계된 AI 모델

자기회귀 모델이거나, 자동 인코딩 모델이거나, 두 가지를 조합한 모델이 LLM

`트랜스포머 아키텍쳐`

`셀프 어텐션`

`NLP (자연어 처리)`

- 자기회귀 작업
    
    이전 토큰을 기반으로 다음 토큰을 예측
    
    트랜스포머 모델의 디코더 부분
    
    어텐션 헤드가 앞서 온 토큰만 볼 수 있도록 ‘전체 문장’에 마스크가 적용되어 있음
    
    ‘생성’에 이상적 ex) GPT
    
- 자동 인코딩 작업
    
    손상된 버전의 입력 내용으로부터 기존 문장을 재구성
    
    트랜스포머 모델의 인코더 부분
    
    전체 문장의 양방향 표현 생성
    
    문장 분류 토큰 분류에 이상적 ex) BERT
    

### 주요 특징

seq2seq

- Encoder : 원시 텍스트 → 핵심 구성 요소로 분리 → 해당 구성 요소를 벡터로 변환
    
    어텐션을 사용하여 텍스트의 맥락 이해
    
- Decoder : 수정된 형식의 어텐션 사용 → 최적의 토큰 예측 → 텍스트 생성

### 작동 원리

사전 훈련 Pre-training

일반적인 언어와 단어 간의 관계를 배우고 이해하는 과정

모든 LLM은 서로 다른 말뭉치와 서로 다른 작업에 대해 훈련됨

전이 학습 Transfer Learning

한 작업에서 얻은 지식을 활용하여 다른 관련 작업의 성능을 향상시키는 기술

### 많이 사용되는 LLM

BERT

GPT-4, ChatGPT

T5

### 도메인 특화 LLM

### LLM을 통한 어플리케이션

전통적 자연어 처리(NLP) 작업

자유로운 텍스트 생성

정보 검색 / 신경망 의미 기반 검색

챗봇